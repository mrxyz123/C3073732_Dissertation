{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c2c0b5",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cfea659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF - Best Parameters: {'rf__max_depth': 30, 'rf__max_features': 'sqrt', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def find_best_params(X_train, y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('rf', RandomForestRegressor(random_state=42))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'rf__n_estimators': [200, 300, 400, 500],\n",
    "        'rf__max_depth': [None, 20, 30, 40],\n",
    "        'rf__min_samples_split': [2, 5, 10],\n",
    "        'rf__min_samples_leaf': [1, 2, 4],\n",
    "        'rf__max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"RF - Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "    return grid_search.best_params_\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"MachineLearinningDataSet.csv\")\n",
    "    target_column = 'Cereal production (metric tons)'\n",
    "    \n",
    "    variables = ['Agriculture, forestry, and fishing, value added (current US$)', \n",
    "                 'Agricultural land (sq. km)', \n",
    "                 'Forest area (sq. km)', \n",
    "                 'Rural population', \n",
    "                 'Agricultural land (% of land area)', \n",
    "                 'Arable land (% of land area)', \n",
    "                 'Agricultural methane emissions (thousand metric tons of CO2 equivalent)', \n",
    "                 'Land under cereal production (hectares)', \n",
    "                 'Average precipitation in depth (mm per year)']\n",
    "\n",
    "    X = df[variables].copy() \n",
    "    y = df[target_column]\n",
    "\n",
    "    # Feature Creation using columns from the original DataFrame\n",
    "    X['arable_land_ratio'] = df['Arable land (hectares)'] / df['Land area (sq. km)']\n",
    "    X['forest_ratio'] = df['Forest area (sq. km)'] / df['Land area (sq. km)']\n",
    "    X['agricultural_land_ratio'] = df['Agricultural land (sq. km)'] / df['Land area (sq. km)']\n",
    "    X['rural_population_density'] = df['Rural population'] / df['Land area (sq. km)']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Find best parameters for RF model\n",
    "    best_params = find_best_params(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba2eba6",
   "metadata": {},
   "source": [
    "# Best Parameter, Cross Validation - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec705302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:\n",
      "Mean MAE: 551689.7434524591\n",
      "Mean SMPE: 20.35047759262318\n",
      "Mean RMSE: 2107075.5321499975\n",
      "Mean R2: 0.9667551183576917\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "def smpe(y_true, y_pred):\n",
    "    return 100 * np.mean(np.abs((y_true - y_pred) / ((y_true + y_pred) / 2)))\n",
    "\n",
    "def train_rf_cv(X, y, n_splits=5):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    cv_scores = {'mae': [], 'rmse': [], 'r2': [], 'smpe': []}\n",
    "    pipelines = []\n",
    "\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('rf', RandomForestRegressor(\n",
    "                n_estimators=500, \n",
    "                max_depth=30, \n",
    "                min_samples_split=2, \n",
    "                min_samples_leaf=1, \n",
    "                max_features='sqrt', \n",
    "                random_state=42))])\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        smpe_score = smpe(y_test, y_pred)\n",
    "\n",
    "        cv_scores['mae'].append(mae)\n",
    "        cv_scores['rmse'].append(rmse)\n",
    "        cv_scores['r2'].append(r2)\n",
    "        cv_scores['smpe'].append(smpe_score)\n",
    "        pipelines.append(pipeline)\n",
    "\n",
    "    print(\"Cross-validation results:\")\n",
    "    print(\"Mean MAE:\", np.mean(cv_scores['mae']))\n",
    "    print(\"Mean SMPE:\", np.mean(cv_scores['smpe']))\n",
    "    print(\"Mean RMSE:\", np.mean(cv_scores['rmse']))\n",
    "    print(\"Mean R2:\", np.mean(cv_scores['r2']))\n",
    "\n",
    "\n",
    "    final_pipeline = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('rf', RandomForestRegressor(\n",
    "            n_estimators=500,\n",
    "            max_depth=30,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features='sqrt',\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    final_pipeline.fit(X, y)\n",
    "    return final_pipeline\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"MachineLearinningDataSet.csv\")\n",
    "    target_column = 'Cereal production (metric tons)'\n",
    "\n",
    "    variables = ['Agriculture, forestry, and fishing, value added (current US$)', \n",
    "                 'Agricultural land (sq. km)', \n",
    "                 'Forest area (sq. km)', \n",
    "                 'Rural population', \n",
    "                 'Agricultural land (% of land area)', \n",
    "                 'Arable land (% of land area)', \n",
    "                 'Agricultural methane emissions (thousand metric tons of CO2 equivalent)', \n",
    "                 'Land under cereal production (hectares)', \n",
    "                 'Average precipitation in depth (mm per year)']\n",
    "\n",
    "    X = df[variables].copy()\n",
    "    y = df[target_column]\n",
    "    \n",
    "    X['arable_land_ratio'] = df['Arable land (hectares)'] / df['Land area (sq. km)']\n",
    "    X['forest_ratio'] = df['Forest area (sq. km)'] / df['Land area (sq. km)']\n",
    "    X['agricultural_land_ratio'] = df['Agricultural land (sq. km)'] / df['Land area (sq. km)']\n",
    "    X['rural_population_density'] = df['Rural population'] / df['Land area (sq. km)']\n",
    "\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "\n",
    "    rf_model = train_rf_cv(X, y, n_splits=5)\n",
    "    \n",
    "    joblib.dump(rf_model, 'random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51317a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 13\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features: {rf_model.named_steps['rf'].n_features_in_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef144816",
   "metadata": {},
   "source": [
    "# Artificial Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f361945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ann_tuning\\cereal_production\\tuner0.json\n",
      "Best Hyperparameters: {'units_1': 480, 'num_layers': 4, 'units_2': 64, 'learning_rate': 0.0001, 'units_3': 320, 'units_4': 128, 'units_5': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_10828\\3367992905.py:7: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from kerastuner import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units=hp.Int('units_1', min_value=32, max_value=512, step=32),\n",
    "                                 activation='relu',\n",
    "                                 input_shape=[X_train_scaled.shape[1]]))\n",
    "    \n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "        model.add(keras.layers.Dense(units=hp.Int(f'units_{i+2}', min_value=32, max_value=512, step=32),\n",
    "                                     activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def find_best_params(X_train_scaled, y_train_scaled, max_trials=10, epochs=100):\n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_loss',\n",
    "        max_trials=max_trials,\n",
    "        executions_per_trial=1,\n",
    "        directory='ann_tuning',\n",
    "        project_name='cereal_production'\n",
    "    )\n",
    "    \n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    tuner.search(X_train_scaled, y_train_scaled,\n",
    "                 epochs=epochs,\n",
    "                 validation_split=0.2,\n",
    "                 callbacks=[early_stop])\n",
    "    \n",
    "    best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "    print(\"Best Hyperparameters:\", best_hyperparameters.values)\n",
    "    \n",
    "    return best_hyperparameters\n",
    "\n",
    "def load_and_preprocess_data(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    target_column = 'Cereal production (metric tons)'\n",
    "    \n",
    "    variables = ['Agriculture, forestry, and fishing, value added (current US$)', \n",
    "                 'Agricultural land (sq. km)', \n",
    "                 'Forest area (sq. km)', \n",
    "                 'Rural population', \n",
    "                 'Agricultural land (% of land area)', \n",
    "                 'Arable land (% of land area)', \n",
    "                 'Agricultural methane emissions (thousand metric tons of CO2 equivalent)', \n",
    "                 'Land under cereal production (hectares)', \n",
    "                 'Average precipitation in depth (mm per year)']\n",
    "    \n",
    "    X = df[variables].copy()\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Feature Creation using columns from the original DataFrame\n",
    "    X['arable_land_ratio'] = df['Arable land (hectares)'] / df['Land area (sq. km)']\n",
    "    X['forest_ratio'] = df['Forest area (sq. km)'] / df['Land area (sq. km)']\n",
    "    X['agricultural_land_ratio'] = df['Agricultural land (sq. km)'] / df['Land area (sq. km)']\n",
    "    X['rural_population_density'] = df['Rural population'] / df['Land area (sq. km)']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def split_and_scale_data(X, y):\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Apply MinMaxScaler to features\n",
    "    X_scaler = MinMaxScaler()\n",
    "    X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    \n",
    "    # Apply MinMaxScaler to target variable\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train_scaled, y_test, y_scaler\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    X, y = load_and_preprocess_data(\"MachineLearinningDataSet.csv\")\n",
    "    \n",
    "    # Split and scale data\n",
    "    X_train_scaled, X_test_scaled, y_train_scaled, y_test, y_scaler = split_and_scale_data(X, y)\n",
    "    \n",
    "    # Find best hyperparameters for ANN model\n",
    "    best_hyperparameters = find_best_params(X_train_scaled, y_train_scaled)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55e0976",
   "metadata": {},
   "source": [
    "# Best Parameter, Cross Validation - ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b4a964a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Mean MAE: 1487108.90177726\n",
      "Mean SMAPE: 88.40906372114145\n",
      "Mean RMSE: 3226804.190204205\n",
      "Mean R2: 0.9255573960443254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(480, activation='relu', input_shape=[input_shape]),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(320, activation='relu'),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def train_ann_cv(X, y, n_splits=5, epochs=100):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    cv_scores = {'mae': [], 'smape': [], 'rmse': [], 'r2': []}\n",
    "    \n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_scaler, y_scaler = MinMaxScaler(), MinMaxScaler()\n",
    "        X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "        X_test_scaled = X_scaler.transform(X_test)\n",
    "        y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "        \n",
    "        model = build_model(X_train_scaled.shape[1])\n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "        \n",
    "        model.fit(X_train_scaled, y_train_scaled, epochs=epochs,\n",
    "                  validation_split=0.2, callbacks=[early_stop], verbose=0)\n",
    "        \n",
    "        y_pred = y_scaler.inverse_transform(model.predict(X_test_scaled)).flatten()\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        smape_score = smape(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        cv_scores['mae'].append(mae)\n",
    "        cv_scores['smape'].append(smape_score)\n",
    "        cv_scores['rmse'].append(rmse)\n",
    "        cv_scores['r2'].append(r2)\n",
    "    \n",
    "    for metric, scores in cv_scores.items():\n",
    "        print(f\"Mean {metric.upper()}: {np.mean(scores)}\")\n",
    "    \n",
    "    final_model = build_model(X.shape[1])\n",
    "    X_scaler, y_scaler = MinMaxScaler(), MinMaxScaler()\n",
    "    final_model.fit(X_scaler.fit_transform(X), y_scaler.fit_transform(y.reshape(-1, 1)),\n",
    "                    epochs=epochs, validation_split=0.2, callbacks=[early_stop], verbose=0)\n",
    "    \n",
    "    return final_model, X_scaler, y_scaler\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"MachineLearinningDataSet.csv\")\n",
    "    target_column = 'Cereal production (metric tons)'\n",
    "    \n",
    "    filter_features = ['Agricultural land (sq. km)', 'Land under cereal production (hectares)', 'Rural population', \n",
    "                       'Average precipitation in depth (mm per year)', 'Agricultural nitrous oxide emissions (thousand metric tons of CO2 equivalent)', \n",
    "                       'Arable land (% of land area)', 'Forest area (sq. km)', 'Surface area (sq. km)', 'Land area (sq. km)', \n",
    "                       'Agricultural methane emissions (thousand metric tons of CO2 equivalent)', 'Agriculture, forestry, and fishing, value added (current US$)', \n",
    "                       'Arable land (hectares)']\n",
    "    \n",
    "    X = df[filter_features].copy()\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Feature engineering using original DataFrame\n",
    "    X['arable_land_ratio'] = df['Arable land (hectares)'] / df['Land area (sq. km)']\n",
    "    X['forest_ratio'] = df['Forest area (sq. km)'] / df['Land area (sq. km)']\n",
    "    X['agricultural_land_ratio'] = df['Agricultural land (sq. km)'] / df['Land area (sq. km)']\n",
    "    X['rural_population_density'] = df['Rural population'] / df['Land area (sq. km)']\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    \n",
    "    ann_model, X_scaler, y_scaler = train_ann_cv(X, y, n_splits=5, epochs=100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447b9d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
